{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhakal/anaconda3/envs/URT_NSCL/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"data/cell_atlas_of_the_human_lung_in_health_and_disease_full.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 106931 × 56239\n",
      "    obs: 'suspension_type', 'donor_id', 'is_primary_data', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'tissue_ontology_term_id', 'organism_ontology_term_id', 'sex_ontology_term_id', \"3'_or_5'\", 'BMI', 'age_or_mean_of_age_range', 'age_range', 'anatomical_region_ccf_score', 'ann_coarse_for_GWAS_and_modeling', 'ann_finest_level', 'ann_level_1', 'ann_level_2', 'ann_level_3', 'ann_level_4', 'ann_level_5', 'cause_of_death', 'core_or_extension', 'dataset', 'fresh_or_frozen', 'log10_total_counts', 'lung_condition', 'mixed_ancestry', 'original_ann_level_1', 'original_ann_level_2', 'original_ann_level_3', 'original_ann_level_4', 'original_ann_level_5', 'original_ann_nonharmonized', 'reannotation_type', 'sample', 'scanvi_label', 'sequencing_platform', 'smoking_status', 'study', 'subject_type', 'tissue_coarse_unharmonized', 'tissue_detailed_unharmonized', 'tissue_dissociation_protocol', 'tissue_level_2', 'tissue_level_3', 'tissue_sampling_method', 'total_counts', 'transf_ann_level_1_label', 'transf_ann_level_1_uncert', 'transf_ann_level_2_label', 'transf_ann_level_2_uncert', 'transf_ann_level_3_label', 'transf_ann_level_3_uncert', 'transf_ann_level_4_label', 'transf_ann_level_4_uncert', 'transf_ann_level_5_label', 'transf_ann_level_5_uncert', 'tissue_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid'\n",
      "    var: 'feature_is_filtered', 'original_gene_symbols', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type'\n",
      "    uns: 'batch_condition', 'citation', 'default_embedding', 'schema_reference', 'schema_version', 'title'\n",
      "    obsm: 'X_scanvi_emb', 'X_umap'\n",
      "    layers: 'soupX'\n",
      "    obsp: 'connectivities', 'distances'\n"
     ]
    }
   ],
   "source": [
    "subset_mask = (\n",
    "    (adata.obs['ann_level_1'] == 'Epithelial') &\n",
    "    (adata.obs['ann_level_2'].isin(['Airway epithelium', 'Alveolar epithelium', 'Submucosal Gland'])) &\n",
    "    (adata.obs['ann_level_3'].isin(['Basal', 'Secretory', 'Submucosal Secretory'])) &\n",
    "    (adata.obs['ann_level_4'].isin(['Basal resting', 'Club', 'Deuterosomal', 'Goblet', \n",
    "                                    'Hillock-like', 'SMG duct', 'SMG mucous', \n",
    "                                    'SMG serous', 'Suprabasal', 'Transitional Club-AT2'])) &\n",
    "    (adata.obs['ann_level_5'].isin(['Club (non-nasal)', 'Goblet (bronchial)', \n",
    "                                    'Goblet (nasal)', 'Goblet (subsegmental)', \n",
    "                                    'SMG serous (bronchial)', 'SMG serous (nasal)', \n",
    "                                    'pre-TB secretory']))\n",
    ")\n",
    "\n",
    "adata = adata[subset_mask].copy()\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 98731 × 56239\n",
      "    obs: 'suspension_type', 'donor_id', 'is_primary_data', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'tissue_ontology_term_id', 'organism_ontology_term_id', 'sex_ontology_term_id', \"3'_or_5'\", 'BMI', 'age_or_mean_of_age_range', 'age_range', 'anatomical_region_ccf_score', 'ann_coarse_for_GWAS_and_modeling', 'ann_finest_level', 'ann_level_1', 'ann_level_2', 'ann_level_3', 'ann_level_4', 'ann_level_5', 'cause_of_death', 'core_or_extension', 'dataset', 'fresh_or_frozen', 'log10_total_counts', 'lung_condition', 'mixed_ancestry', 'original_ann_level_1', 'original_ann_level_2', 'original_ann_level_3', 'original_ann_level_4', 'original_ann_level_5', 'original_ann_nonharmonized', 'reannotation_type', 'sample', 'scanvi_label', 'sequencing_platform', 'smoking_status', 'study', 'subject_type', 'tissue_coarse_unharmonized', 'tissue_detailed_unharmonized', 'tissue_dissociation_protocol', 'tissue_level_2', 'tissue_level_3', 'tissue_sampling_method', 'total_counts', 'transf_ann_level_1_label', 'transf_ann_level_1_uncert', 'transf_ann_level_2_label', 'transf_ann_level_2_uncert', 'transf_ann_level_3_label', 'transf_ann_level_3_uncert', 'transf_ann_level_4_label', 'transf_ann_level_4_uncert', 'transf_ann_level_5_label', 'transf_ann_level_5_uncert', 'tissue_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'observation_joinid'\n",
      "    var: 'feature_is_filtered', 'original_gene_symbols', 'feature_name', 'feature_reference', 'feature_biotype', 'feature_length', 'feature_type'\n",
      "    uns: 'batch_condition', 'citation', 'default_embedding', 'schema_reference', 'schema_version', 'title'\n",
      "    obsm: 'X_scanvi_emb', 'X_umap'\n",
      "    layers: 'soupX'\n",
      "    obsp: 'connectivities', 'distances'\n"
     ]
    }
   ],
   "source": [
    "desired_diseases = [\"normal\", \"chronic obstructive pulmonary disease\", \"chronic rhinitis\", \"pulmonary fibrosis\"]\n",
    "adata = adata[adata.obs['disease'].isin(desired_diseases)].copy()\n",
    "print(adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_cells(adata, min_counts=500)\n",
    "sc.pp.filter_genes(adata, min_cells=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhakal/anaconda3/envs/URT_NSCL/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:75: UserWarning: `flavor='seurat_v3'` expects raw count data, but non-integers were found.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sc.pp.highly_variable_genes(adata, n_top_genes=4000, flavor='seurat_v3')\n",
    "adata = adata[:, adata.var['highly_variable']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chronic obstructive pulmonary disease' 'chronic rhinitis' 'normal'\n",
      " 'pulmonary fibrosis']\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "adata.obs['disease_encoded'] = le.fit_transform(adata.obs['disease'])\n",
    "disease_classes = le.classes_  # This will store the class order\n",
    "print(disease_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple split: 80% train, 10% val, 10% test\n",
    "all_indices = np.arange(adata.n_obs)\n",
    "np.random.shuffle(all_indices)\n",
    "\n",
    "train_size = int(0.8 * len(all_indices))\n",
    "val_size = int(0.1 * len(all_indices))\n",
    "test_size = len(all_indices) - train_size - val_size\n",
    "\n",
    "train_idx = all_indices[:train_size]\n",
    "val_idx = all_indices[train_size:train_size+val_size]\n",
    "test_idx = all_indices[train_size+val_size:]\n",
    "\n",
    "X = adata.X\n",
    "\n",
    "# Convert to np.array if not already\n",
    "X = X.toarray() if hasattr(X, 'toarray') else X\n",
    "\n",
    "y = adata.obs['disease_encoded'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = MyDataset(X[train_idx], y[train_idx])\n",
    "val_dataset = MyDataset(X[val_idx], y[val_idx])\n",
    "test_dataset = MyDataset(X[test_idx], y[test_idx])\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]\n",
    "num_classes = len(disease_classes)\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256, num_classes=4):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN(input_dim=input_dim, num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.0546, Train Acc: 0.9805, Val Loss: 0.0305, Val Acc: 0.9876\n",
      "Epoch 2/10, Train Loss: 0.0290, Train Acc: 0.9888, Val Loss: 0.0333, Val Acc: 0.9873\n",
      "Epoch 3/10, Train Loss: 0.0206, Train Acc: 0.9921, Val Loss: 0.0343, Val Acc: 0.9888\n",
      "Epoch 4/10, Train Loss: 0.0165, Train Acc: 0.9939, Val Loss: 0.0295, Val Acc: 0.9896\n",
      "Epoch 5/10, Train Loss: 0.0130, Train Acc: 0.9953, Val Loss: 0.0371, Val Acc: 0.9860\n",
      "Epoch 6/10, Train Loss: 0.0100, Train Acc: 0.9964, Val Loss: 0.0357, Val Acc: 0.9909\n",
      "Epoch 7/10, Train Loss: 0.0093, Train Acc: 0.9968, Val Loss: 0.0345, Val Acc: 0.9901\n",
      "Epoch 8/10, Train Loss: 0.0072, Train Acc: 0.9974, Val Loss: 0.0372, Val Acc: 0.9892\n",
      "Epoch 9/10, Train Loss: 0.0065, Train Acc: 0.9975, Val Loss: 0.0412, Val Acc: 0.9895\n",
      "Epoch 10/10, Train Loss: 0.0054, Train Acc: 0.9982, Val Loss: 0.0407, Val Acc: 0.9897\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x, batch_y\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * batch_x.size(0)\n",
    "        _, pred = outputs.max(1)\n",
    "        correct += pred.eq(batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "    \n",
    "    train_loss /= total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # Validate\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x, batch_y\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item() * batch_x.size(0)\n",
    "            _, pred = outputs.max(1)\n",
    "            val_correct += pred.eq(batch_y).sum().item()\n",
    "            val_total += batch_y.size(0)\n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0392, Test Acc: 0.9918\n",
      "Train Loss: 0.0000, Train Acc: 0.9982\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x, batch_y = batch_x, batch_y\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        test_loss += loss.item() * batch_x.size(0)\n",
    "        _, pred = outputs.max(1)\n",
    "        test_correct += pred.eq(batch_y).sum().item()\n",
    "        test_total += batch_y.size(0)\n",
    "        all_preds.append(pred.cpu().numpy())\n",
    "        all_targets.append(batch_y.cpu().numpy())\n",
    "\n",
    "test_loss /= test_total\n",
    "test_acc = test_correct / test_total\n",
    "train_loss /= total\n",
    "train_acc = correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a small sample of the test set\n",
    "sample_size = 2000\n",
    "sample_idx = np.random.choice(test_idx, sample_size, replace=False)\n",
    "X_sample = X[sample_idx]\n",
    "X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "\n",
    "model.eval()\n",
    "background = X[train_idx][:1000]  # background for SHAP\n",
    "background = torch.tensor(background, dtype=torch.float32)\n",
    "background = background.detach()\n",
    "explainer = shap.DeepExplainer(model, background)\n",
    "# explainer.explainer.multi_input, explainer.explainer.multi_output = True, True\n",
    "shap_values = explainer.shap_values(X_sample, check_additivity=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 important genes identified by SHAP:\n",
      "ENSG00000175899\n",
      "ENSG00000197953\n",
      "ENSG00000184389\n",
      "ENSG00000114771\n"
     ]
    }
   ],
   "source": [
    "# Assuming shap_values is a list of arrays with shape [num_classes, sample_size, num_genes]\n",
    "# Convert to a numpy array if needed\n",
    "shap_array = np.array(shap_values)  # shape: (num_classes, sample_size, num_genes)\n",
    "\n",
    "# Compute the average absolute SHAP value across classes and samples\n",
    "shap_avg = np.mean(np.abs(shap_array), axis=(0, 1))  # shape: (num_genes,)\n",
    "\n",
    "# Get gene names from adata.var_names\n",
    "gene_names = adata.var_names\n",
    "\n",
    "# Sort genes by importance (descending order)\n",
    "important_genes_idx = np.argsort(shap_avg)[::-1]\n",
    "\n",
    "# Extract top 20 genes\n",
    "top_20_genes = gene_names[important_genes_idx[:20]]\n",
    "\n",
    "print(\"Top 20 important genes identified by SHAP:\")\n",
    "for gene in top_20_genes:\n",
    "    print(gene)\n",
    "\n",
    "# If you want a SHAP summary plot for a single class:\n",
    "# shap.summary_plot(shap_values[0], features=X_sample, feature_names=gene_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "URT_NSCL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
